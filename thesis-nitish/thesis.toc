\contentsline {chapter}{Abstract}{v}{Doc-Start}
\contentsline {chapter}{List of Tables}{xv}{chapter*.4}
\contentsline {chapter}{List of Figures}{xvii}{chapter*.5}
\contentsline {chapter}{List of Algorithms}{xix}{chapter*.6}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.7}
\contentsline {section}{\numberline {1.1}Motivation}{3}{section.9}
\contentsline {subsection}{\numberline {1.1.1}Inability to preserve word ordering}{3}{subsection.10}
\contentsline {subsection}{\numberline {1.1.2}Lack of similarity measures}{4}{subsection.11}
\contentsline {subsection}{\numberline {1.1.3}Compositionality of distributed word vectors}{4}{subsection.12}
\contentsline {section}{\numberline {1.2}Problem Statement}{5}{section.13}
\contentsline {section}{\numberline {1.3}Contributions of the Thesis}{6}{section.15}
\contentsline {section}{\numberline {1.4}Organization of the Thesis}{6}{section.16}
\contentsline {chapter}{\numberline {2}Background on Document Categorization}{7}{chapter.17}
\contentsline {section}{\numberline {2.1}Text Representation}{7}{section.18}
\contentsline {subsection}{\numberline {2.1.1}Bag of Words}{8}{subsection.19}
\contentsline {subsection}{\numberline {2.1.2}Dimensionality Reduction and Feature Selection}{9}{subsection.21}
\contentsline {section}{\numberline {2.2}Learning Algorithms}{11}{section.26}
\contentsline {subsection}{\numberline {2.2.1}Document Categorization using Binary Classifiers}{12}{subsection.27}
\contentsline {subsection}{\numberline {2.2.2}Document Categorization with Single Joint Classifier}{14}{subsection.28}
\contentsline {chapter}{\numberline {3}Distributed Document Representations}{17}{chapter.30}
\contentsline {section}{\numberline {3.1}Need for Distributed Word Representations}{17}{section.31}
\contentsline {section}{\numberline {3.2}Background on Word Embeddings}{18}{section.34}
\contentsline {subsection}{\numberline {3.2.1}Neural Probabilistic Language Model}{19}{subsection.35}
\contentsline {subsection}{\numberline {3.2.2}Log-Linear Models}{20}{subsection.42}
\contentsline {subsubsection}{\numberline {3.2.2.1}Continuous Bag-of-Words Model}{21}{subsubsection.43}
\contentsline {subsubsection}{\numberline {3.2.2.2}Continuous Skip-gram Model}{22}{subsubsection.48}
\contentsline {subsubsection}{\numberline {3.2.2.3}Dependency-based Word Embeddings}{23}{subsubsection.51}
\contentsline {section}{\numberline {3.3}Document Representation}{24}{section.53}
\contentsline {subsection}{\numberline {3.3.1}Problem Setup}{25}{subsection.56}
\contentsline {subsection}{\numberline {3.3.2}Our Model}{25}{subsection.57}
\contentsline {subsubsection}{\numberline {3.3.2.1}Context Representation}{26}{subsubsection.62}
\contentsline {subsubsection}{\numberline {3.3.2.2}Estimating Prediction Probability}{27}{subsubsection.64}
\contentsline {subsubsection}{\numberline {3.3.2.3}Learning Objective}{28}{subsubsection.69}
\contentsline {subsubsection}{\numberline {3.3.2.4}Noise Contrastive Estimation}{29}{subsubsection.73}
\contentsline {subsubsection}{\numberline {3.3.2.5}Learning Objective using NCE}{30}{subsubsection.77}
\contentsline {subsubsection}{\numberline {3.3.2.6}Parameter Estimation}{31}{subsubsection.81}
\contentsline {subsubsection}{\numberline {3.3.2.7}Hyper-parameters of our model}{34}{subsubsection.108}
\contentsline {chapter}{\numberline {4}Multi-Label Document Categorization}{37}{chapter.115}
\contentsline {section}{\numberline {4.1}Logistic Regression for Multi-label Document Categorization}{37}{section.116}
\contentsline {subsection}{\numberline {4.1.1}Training Data}{38}{subsection.117}
\contentsline {subsection}{\numberline {4.1.2}Logistic Regression Model}{39}{subsection.118}
\contentsline {subsubsection}{\numberline {4.1.2.1}Learning Objective}{39}{subsubsection.120}
\contentsline {subsubsection}{\numberline {4.1.2.2}Parameter Estimation}{40}{subsubsection.127}
\contentsline {section}{\numberline {4.2}Similarity to Relational Learning}{42}{section.135}
\contentsline {section}{\numberline {4.3}Advantages of Logistic Regression Learning Algorithm}{43}{section.139}
\contentsline {chapter}{\numberline {5}Performance Evaluation}{45}{chapter.144}
\contentsline {section}{\numberline {5.1}Datasets}{45}{section.145}
\contentsline {subsection}{\numberline {5.1.1}Reuters-21578}{46}{subsection.146}
\contentsline {subsection}{\numberline {5.1.2}Wikipedia Datasets}{47}{subsection.148}
\contentsline {section}{\numberline {5.2}Experimental Setup}{48}{section.151}
\contentsline {section}{\numberline {5.3}Results}{51}{section.156}
\contentsline {subsection}{\numberline {5.3.1}Document Categorization}{51}{subsection.157}
\contentsline {subsubsection}{\numberline {5.3.1.1}Reuters - 21578}{52}{subsubsection.158}
\contentsline {subsubsection}{\numberline {5.3.1.2}Physics - Wikipedia}{54}{subsubsection.165}
\contentsline {subsubsection}{\numberline {5.3.1.3}Biology - Wikipedia}{56}{subsubsection.172}
\contentsline {subsubsection}{\numberline {5.3.1.4}Mathematics - Wikipedia}{58}{subsubsection.179}
\contentsline {subsubsection}{\numberline {5.3.1.5}Sports - Wikipedia}{60}{subsubsection.186}
\contentsline {subsection}{\numberline {5.3.2}Imputing Missing Categories}{62}{subsection.193}
\contentsline {subsection}{\numberline {5.3.3}Estimating Similarity between Categories and Words}{64}{subsection.195}
\contentsline {chapter}{\numberline {6}Conclusions and Future Work}{67}{chapter.197}
\contentsline {section}{\numberline {6.1}Future Work}{68}{section.198}
\contentsline {subsection}{\numberline {6.1.1}Improving Compositionality of Word Vectors}{68}{subsection.199}
\contentsline {subsection}{\numberline {6.1.2}Joint Document Representation Learning and Document Categorization}{69}{subsection.200}
\contentsline {subsection}{\numberline {6.1.3}Supervised Multi-view Relational Learning}{69}{subsection.201}
\contentsline {chapter}{Bibliography}{71}{subsection.201}
