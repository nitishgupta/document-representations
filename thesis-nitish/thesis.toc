\contentsline {chapter}{Abstract}{v}{Doc-Start}
\contentsline {chapter}{List of Tables}{xv}{chapter*.4}
\contentsline {chapter}{List of Figures}{xvii}{chapter*.5}
\contentsline {chapter}{List of Algorithms}{xix}{chapter*.6}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.7}
\contentsline {section}{\numberline {1.1}Motivation}{3}{section.9}
\contentsline {subsection}{\numberline {1.1.1}Inability to preserve word ordering}{3}{subsection.10}
\contentsline {subsection}{\numberline {1.1.2}Lack of similarity measures}{4}{subsection.11}
\contentsline {subsection}{\numberline {1.1.3}Compositionality of distributed word vectors}{4}{subsection.12}
\contentsline {section}{\numberline {1.2}Problem Statement}{5}{section.13}
\contentsline {section}{\numberline {1.3}Contributions of the Thesis}{6}{section.15}
\contentsline {section}{\numberline {1.4}Organization of the Thesis}{6}{section.16}
\contentsline {chapter}{\numberline {2}Background on Document Categorization}{7}{chapter.17}
\contentsline {section}{\numberline {2.1}Text Representation}{7}{section.18}
\contentsline {subsection}{\numberline {2.1.1}Bag of Words}{8}{subsection.19}
\contentsline {subsection}{\numberline {2.1.2}Dimensionality Reduction and Feature Selection}{9}{subsection.21}
\contentsline {section}{\numberline {2.2}Learning Algorithms}{12}{section.27}
\contentsline {subsection}{\numberline {2.2.1}Document Categorization using Binary Classifiers}{13}{subsection.28}
\contentsline {subsection}{\numberline {2.2.2}Document Categorization with Single Joint Classifier}{15}{subsection.29}
\contentsline {chapter}{\numberline {3}Distributed Document Representations}{19}{chapter.34}
\contentsline {section}{\numberline {3.1}Need for Distributed Word Representations}{19}{section.35}
\contentsline {section}{\numberline {3.2}Background on Word Embeddings}{20}{section.38}
\contentsline {subsection}{\numberline {3.2.1}Neural Probabilistic Language Model}{21}{subsection.39}
\contentsline {subsection}{\numberline {3.2.2}Log-Linear Models}{22}{subsection.46}
\contentsline {subsubsection}{\numberline {3.2.2.1}Continuous Bag-of-Words Model}{23}{subsubsection.47}
\contentsline {subsubsection}{\numberline {3.2.2.2}Continuous Skip-gram Model}{24}{subsubsection.52}
\contentsline {subsubsection}{\numberline {3.2.2.3}Dependency-based Word Embeddings}{25}{subsubsection.55}
\contentsline {section}{\numberline {3.3}Document Representation}{26}{section.57}
\contentsline {subsection}{\numberline {3.3.1}Problem Setup}{27}{subsection.60}
\contentsline {subsection}{\numberline {3.3.2}Our Model}{27}{subsection.61}
\contentsline {subsubsection}{\numberline {3.3.2.1}Context Representation}{28}{subsubsection.66}
\contentsline {subsubsection}{\numberline {3.3.2.2}Estimating Prediction Probability}{29}{subsubsection.68}
\contentsline {subsubsection}{\numberline {3.3.2.3}Learning Objective}{30}{subsubsection.73}
\contentsline {subsubsection}{\numberline {3.3.2.4}Noise Contrastive Estimation}{31}{subsubsection.77}
\contentsline {subsubsection}{\numberline {3.3.2.5}Learning Objective using NCE}{32}{subsubsection.81}
\contentsline {subsubsection}{\numberline {3.3.2.6}Parameter Estimation}{33}{subsubsection.85}
\contentsline {subsubsection}{\numberline {3.3.2.7}Hyper-parameters of our model}{36}{subsubsection.112}
\contentsline {chapter}{\numberline {4}Multi-Label Document Categorization}{39}{chapter.119}
\contentsline {section}{\numberline {4.1}Logistic Regression for Multi-label Document Categorization}{39}{section.120}
\contentsline {subsection}{\numberline {4.1.1}Training Data}{40}{subsection.121}
\contentsline {subsection}{\numberline {4.1.2}Logistic Regression Model}{41}{subsection.122}
\contentsline {subsubsection}{\numberline {4.1.2.1}Learning Objective}{41}{subsubsection.124}
\contentsline {subsubsection}{\numberline {4.1.2.2}Parameter Estimation}{42}{subsubsection.131}
\contentsline {section}{\numberline {4.2}Similarity to Relational Learning}{44}{section.139}
\contentsline {section}{\numberline {4.3}Advantages of Logistic Regression Learning Algorithm}{45}{section.143}
\contentsline {chapter}{\numberline {5}Performance Evaluation}{47}{chapter.148}
\contentsline {section}{\numberline {5.1}Datasets}{47}{section.149}
\contentsline {subsection}{\numberline {5.1.1}Reuters-21578}{48}{subsection.150}
\contentsline {subsection}{\numberline {5.1.2}Wikipedia Datasets}{49}{subsection.152}
\contentsline {section}{\numberline {5.2}Experimental Setup}{50}{section.155}
\contentsline {section}{\numberline {5.3}Results}{53}{section.160}
\contentsline {subsection}{\numberline {5.3.1}Document Categorization}{53}{subsection.161}
\contentsline {subsubsection}{\numberline {5.3.1.1}Reuters - 21578}{54}{subsubsection.162}
\contentsline {subsubsection}{\numberline {5.3.1.2}Physics - Wikipedia}{56}{subsubsection.169}
\contentsline {subsubsection}{\numberline {5.3.1.3}Biology - Wikipedia}{58}{subsubsection.176}
\contentsline {subsubsection}{\numberline {5.3.1.4}Mathematics - Wikipedia}{60}{subsubsection.183}
\contentsline {subsubsection}{\numberline {5.3.1.5}Sports - Wikipedia}{62}{subsubsection.190}
\contentsline {subsection}{\numberline {5.3.2}Imputing Missing Categories}{64}{subsection.197}
\contentsline {subsection}{\numberline {5.3.3}Estimating Similarity between Categories and Words}{66}{subsection.199}
\contentsline {chapter}{\numberline {6}Conclusions and Future Work}{69}{chapter.201}
\contentsline {section}{\numberline {6.1}Future Work}{70}{section.202}
\contentsline {subsection}{\numberline {6.1.1}Improving Compositionality of Word Vectors}{70}{subsection.203}
\contentsline {subsection}{\numberline {6.1.2}Joint Document Representation Learning and Document Categorization}{71}{subsection.204}
\contentsline {subsection}{\numberline {6.1.3}Supervised Multi-view Relational Learning}{71}{subsection.205}
\contentsline {chapter}{Bibliography}{73}{subsection.205}
