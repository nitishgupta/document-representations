\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Distributed Document Embeddings}{15}{chapter.37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:distembed}{{3}{15}{Distributed Document Embeddings}{chapter.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivation}{15}{section.38}}
\newlabel{sec:motivation_distributed}{{3.1}{15}{Motivation}{section.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Background on Word Embeddings}{16}{section.41}}
\newlabel{sec:background_distributed}{{3.2}{16}{Background on Word Embeddings}{section.41}{}}
\citation{bengio2003neural}
\citation{mnih2013learning}
\citation{mikolov2013distributed}
\citation{collobert2011natural}
\citation{bottou2014machine}
\citation{turian2010word}
\citation{levy2014dependencybased}
\citation{bengio2003neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Neural Probabilistic Language Model}{17}{subsection.42}}
\newlabel{sec:bengio}{{3.2.1}{17}{Neural Probabilistic Language Model}{subsection.42}{}}
\citation{mikolov2013efficient}
\citation{mikolov2013efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Bengio's Neural Network Architecture for Neural Probabilistic Language Model\relax }}{18}{figure.caption.45}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nn:bengio}{{3.1}{18}{Bengio's Neural Network Architecture for Neural Probabilistic Language Model\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Log-Linear Models}{19}{subsection.49}}
\newlabel{sec:word2vec}{{3.2.2}{19}{Log-Linear Models}{subsection.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.1}Continuous Bag-of-Words}{19}{subsubsection.50}}
\newlabel{sec:cbow}{{3.2.2.1}{19}{Continuous Bag-of-Words}{subsubsection.50}{}}
\newlabel{eq:cbow:prob}{{3.8}{19}{Continuous Bag-of-Words}{equation.54}{}}
\citation{morin2005hierarchical}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Continuous Bag-of-Words Model (CBOW) \leavevmode {\color  {red}\textbf  {TODO:} Add ref?}\relax }}{20}{figure.caption.51}}
\newlabel{fig:nn:cbow}{{3.2}{20}{Continuous Bag-of-Words Model (CBOW) \todo {Add ref?}\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.2}Continuous Skip-gram}{20}{subsubsection.55}}
\newlabel{eq:skip:prob}{{3.9}{20}{Continuous Skip-gram}{equation.57}{}}
\citation{mikolov2013linguistic}
\citation{levy2014dependencybased}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Continuous Skip-gram Model \leavevmode {\color  {red}\textbf  {TODO:} Add ref?}\relax }}{21}{figure.caption.56}}
\newlabel{fig:nn:skip}{{3.3}{21}{Continuous Skip-gram Model \todo {Add ref?}\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.3}Dependency-based Word Embeddings}{21}{subsubsection.58}}
\citation{mitchell2010composition}
\citation{zanzotto2010estimating}
\citation{yessenalina2011compositional}
\citation{grefenstette2013multi}
\citation{mikolov2013distributed}
\citation{socher2013recursive}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Dependency-based context extraction example \leavevmode {\color  {red}\textbf  {TODO:} Add ref?}\relax }}{22}{figure.caption.59}}
\newlabel{fig:dep:context}{{3.4}{22}{Dependency-based context extraction example \todo {Add ref?}\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Document Embeddings}{22}{section.60}}
\newlabel{sec:document_embeddings}{{3.3}{22}{Document Embeddings}{section.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Problem Setup}{23}{subsection.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Our Model}{24}{subsection.64}}
\newlabel{sec:docem_ourmodel}{{3.3.2}{24}{Our Model}{subsection.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces GloDETC : Neural Network Architecture \leavevmode {\color  {red}\textbf  {TODO:} Change figure}\relax }}{25}{figure.caption.68}}
\newlabel{fig:nn:archi}{{3.5}{25}{GloDETC : Neural Network Architecture \todo {Change figure}\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.1}Projection Layer (Context Representation)}{25}{subsubsection.69}}
\newlabel{eq:hidden_vec}{{3.10}{26}{Projection Layer (Context Representation)}{equation.70}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.2}Estimating Prediction Probability}{26}{subsubsection.71}}
\newlabel{eq:nn_score}{{3.11}{26}{Estimating Prediction Probability}{equation.73}{}}
\newlabel{eq:soft_prob}{{3.12}{26}{Estimating Prediction Probability}{equation.75}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.3}Training Objective}{26}{subsubsection.76}}
\citation{morin2005hierarchical}
\citation{bengio2003quick}
\citation{bengio2008adaptive}
\citation{gutmann2012noise}
\citation{mnih2012fast}
\citation{mnih2013learning}
\newlabel{eq:paramter_argmax}{{3.13}{27}{Training Objective}{equation.77}{}}
\newlabel{eq:training_objective}{{3.14}{27}{Training Objective}{equation.78}{}}
\newlabel{eq:update_theta}{{3.15}{27}{Training Objective}{equation.79}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.4}Noise Contrastive Estimation}{27}{subsubsection.80}}
\newlabel{eq:label1}{{3.16}{28}{Noise Contrastive Estimation}{equation.81}{}}
\newlabel{eq:label0}{{3.17}{29}{Noise Contrastive Estimation}{equation.82}{}}
\newlabel{eq:prob_y}{{3.18}{29}{Noise Contrastive Estimation}{equation.83}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.5}New Training Objective}{29}{subsubsection.84}}
\newlabel{eq:new_argmax}{{3.19}{29}{New Training Objective}{equation.85}{}}
\newlabel{eq:new_training_objective}{{3.20}{29}{New Training Objective}{equation.86}{}}
\newlabel{eq:log_P}{{3.21}{29}{New Training Objective}{equation.87}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.6}Parameter Estimation}{29}{subsubsection.88}}
\newlabel{sec:para_esti_doc}{{3.3.2.6}{29}{Parameter Estimation}{subsubsection.88}{}}
\newlabel{eq:partial_theta}{{3.25}{30}{Parameter Estimation}{equation.92}{}}
\newlabel{eq:partial_doc}{{3.26}{30}{Parameter Estimation}{equation.93}{}}
\newlabel{eq:partial_w_t}{{3.27}{30}{Parameter Estimation}{equation.94}{}}
\newlabel{eq:partial_w_t-k}{{3.28}{30}{Parameter Estimation}{equation.95}{}}
\newlabel{eq:partial_wgt_t-k}{{3.29}{30}{Parameter Estimation}{equation.96}{}}
\newlabel{eq:grad_doc}{{3.30}{31}{Parameter Estimation}{equation.98}{}}
\newlabel{eq:grad_mword}{{3.31}{31}{Parameter Estimation}{equation.100}{}}
\newlabel{eq:grad_cword}{{3.32}{31}{Parameter Estimation}{equation.102}{}}
\newlabel{eq:grad_wgt}{{3.33}{31}{Parameter Estimation}{equation.104}{}}
\newlabel{eq:update_reg}{{3.34}{31}{Parameter Estimation}{equation.105}{}}
\newlabel{eq:update_doc}{{3.35}{31}{Parameter Estimation}{equation.107}{}}
\newlabel{eq:update_mword}{{3.36}{32}{Parameter Estimation}{equation.109}{}}
\newlabel{eq:update_cword}{{3.37}{32}{Parameter Estimation}{equation.111}{}}
\newlabel{eq:update_wgt}{{3.38}{32}{Parameter Estimation}{equation.113}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.7}Hyper-parameters}{32}{subsubsection.115}}
\newlabel{sec:hp_doc}{{3.3.2.7}{32}{Hyper-parameters}{subsubsection.115}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Learning Document and Word Vector Representations\relax }}{33}{algorithm.114}}
\newlabel{alg:doc_embeddings}{{1}{33}{Learning Document and Word Vector Representations\relax }{algorithm.114}{}}
\@setckpt{DistributedEmbeddings}{
\setcounter{page}{35}
\setcounter{equation}{38}
\setcounter{enumi}{6}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{2}
\setcounter{subsubsection}{7}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{16}
\setcounter{algorithm}{1}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{lstnumber}{1}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{38}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{30}
\setcounter{AM@survey}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{example}{0}
\setcounter{definition}{0}
\setcounter{proposition}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{3}
}
