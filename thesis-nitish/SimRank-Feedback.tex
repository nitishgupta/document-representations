\chapter{Semi-Supervised Synset Similarity}
\label{chapter:Semi-SupervisedSynsetSimilarity}
In this chapter, we describe the idea of SimRank, its personalization and application to learning synset similarity in a semi-supervised fashion. Further we discuss how to coarsen the WordNet taxonomy and evaluate the clustering obtained in a WSD task based setting.

\section{Motivation}
The small coverage of the Support Vector Machines that we saw in section \ref{sec:supervisedAlgoOutline} makes them unsuitable to be used as a generic synset similarity estimator. To learn the similarity between synsets which do not share a word, we wish to utilize the relations encoded in WordNet as well as the information learnt using supervision. 
The ability of the Personalized SimRank framework to propogate the seeded information using semantic links between concepts allows us to learn complete synset similarity estimates.

\section{SimRank}
\label{sec:SimRank}
\subsection{Introduction}
SimRank, proposed in \citep{Jeh02simrank}, is a graph based similarity measure applicable in any domain with object-to-object relationships. The basic intuition behind the SimRank approach is: ``\textbf{two objects are similar if they are referenced by similar objects}'' \citep{Jeh02simrank} \citep{LizorkinSimrank}. Note the given intuition is recursive in nature, so the base cases play an important role here.

Before discussing the model, let us introduce some notation for convenience. Given a graph $G(V,E)$ consisting of a set of nodes $V$ and a set of links $E$, the following two mappings are further assumed defined for each node $v \in V$ in the graph:
\begin{itemize}
\item $I(v)$ denotes all in-neighbours of a node $v$ i.e.
\begin{equation}
I(v) = \{u\in V | (u,v)\in E\}
\end{equation}
\item $O(v)$ denotes all out-neighbours of a node $v$ i.e.
\begin{equation}
O(v) = \{w\in V | (v,w)\in E\}
\end{equation}
\end{itemize}

Notations $|I(v)|$ and $|O(v)|$ denote the number of nodes in $I(v)$ and $O(v)$ respectively. 
Individual member of $I(v)$ and $O(v)$ are referred to as $I_i(v)$, $1\leq i \leq |I(v)|$ and $O_j(v)$, $1\leq j \leq |O(v)|$.

With the similarity score between objects $a$ and $b$ denoted by $s(a,b)\in [0,1]$, the basic SimRank intuition is then written as follows: 
\begin{equation} \label{eq:SimRankBasic}
s(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b \\
0 &  \mbox{ if } I(a)=\phi \mbox{ or } I(b)=\phi \\
\frac{C}{|I(a)||I(b)|}\sum_{i=1}^{|I(a)|}\sum_{j=1}^{|I(b)|} s(I_i(a),I_j(b)) & \mbox{ otherwise } \\
\end{array}\right.
\end{equation}
with a constant $C$ being the decay factor, $0 < C < 1$.

\subsection{Solution and its Properties}
The solution to the SimRank equation \ref{eq:SimRankBasic} for a graph $G(V,E)$ is reached by iteration to a fixed-point. 
For each iteration $k$, we keep ${|V|}^2$ entries $R_k(\ast,\ast)$, where $R_k(a,b)$ gives the score between $a$ and $b$ on iteration $k$.
We start with $R_0(\ast,\ast)$ defined as:
\begin{equation}
R_0(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b \\
0 & \mbox{otherwise}
\end{array}\right.
\end{equation}

We successively compute $R_{k+1}(\ast,\ast)$ based on $R_k(\ast,\ast)$:
\begin{equation} \label{eq:SimRankBasicRecursive}
R_{k+1}(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b \\
0 &  \mbox{if } I(a)=\phi \mbox{ or } I(b)=\phi \\
\frac{C}{|I(a)||I(b)|}\sum_{i=1}^{|I(a)|}\sum_{j=1}^{|I(b)|} R_k(I_i(a),I_j(b)) & \mbox{otherwise } \\
\end{array}\right.
\end{equation}

Let us highlight some properties of SimRank covered in \citep{Jeh02simrank} and \citep{LizorkinSimrank}:
\begin{enumerate}
\item A solution $s(\ast,\ast)$ to SimRank equations always exist and is unique, and $s(\ast,\ast) \in [0,1]$
\item For each $k$, $R_k(\ast,\ast)$ is a lower bound on the SimRank function $s(\ast,\ast)$ i.e $R_k(a,b) \leq s(a.b)$
\item Iterative functions $R_k(\ast,\ast)$ converge to SimRank function $s(\ast,\ast)$ i.e. 
\begin{equation}
\displaystyle \lim_{k \rightarrow \infty}R_k(a,b)=s(a,b)
\end{equation}
\item The difference between SimRank theoretical scores and iterative similarity scores decreases exponentially in the number of iterations and uniformly for every pair of nodes. Formally, for every iteration number $k=0,1,2,\ldots$ and for every two nodes $a,b$, the following estimate holds
\begin{equation} \label{SimRankExponentialConvergence}
s(a,b) - R_k(a,b) \leq C^{k+1}
\end{equation}
\end{enumerate}

\subsection{Random Surfer Pair Model}
\citep{Jeh02simrank} show that the SimRank similarity score $s(a,b)$ measures how soon two random surfers are expected to meet at the same node if they start at nodes $a$ and $b$ and randomly walk the graph backwards.

\begin{equation}
s(a,b) = \sum_{t:(a,b) \rightsquigarrow (x,x)} P[t]C^{l(t)}  \label{eq:emd} 
\end{equation}

More formally, $s(a,b)$ is the \textit{expected f-meeting distance} traveling back edges, between the nodes $a$ and $b$ with $f(z)=C^z$.

\section{Personalized Weighted SimRank}
\subsection{Weighted SimRank}
Many times while working with real data, we observe relationships of different types between objects, which are likely to have different weights associated with them. For learning similarity between objects having such underlying structure, we discuss a weighted version of the SimRank method proposed in \citep{Jeh02simrank} and discussed in section \ref{sec:SimRank}. For convenience, let us define $W_{I}(n)$ and $W_{O}(n)$, for a node $n$ as follows:
\begin{align}
W_{O}(n) &= \sum_{i=1}^{|O(n)|} w(n,O_i(n)) \\
W_{I}(n) &= \sum_{i=1}^{|I(n)|} w(I_i(n),n)
\end{align}

Let us denote the similarity between objects $a$ and $b$ by $s(a,b) \in [0,1]$.
Following the motivation above, we write the recursive equation for $s(a,b)$.
If $a = b$ then $s(a,b)$ is defined to be 1. Otherwise 

\begin{align}
s(a,b) = \frac{C}{W_{I}(a)W_{I}(b)} \sum_{i=1}^{|I(a)|} \sum_{j=1}^{|I(b)|} w(I_i(a),a) \cdot w(I_j(b),b) \cdot s(I_i(a),I_j(b)) \label{eq:SimRankWeighted}
\end{align}

\noindent
The relation \ref{eq:SimRankWeighted} is obtained by extending the Random Surfer Pairs Model of SimRank and is discussed in more detail in Appendix \ref{appendix:weightedSimRank}.

\subsection{Personalizing SimRank}
\label{subsection:PersonalizedSimRank}
In many scenarios, while working with objects, we don't have complete information about the objects and thus have similarities for only some pair of objects. These similarities may be independently learnt and may not directly conform with the underlying graph. In such situations, we would like to get a more complete and consistent similarity metric between objects but we would like to use the information given to us as well. For the same, we propose a personalized framework for SimRank, in which we bias the SimRank by changing the initialization.
If we know similarities of some pairs, we fix them in our set of equations and let the rest of the values be automatically learned by the system.

Lets call the map of node pairs to their similarity values as $InitStore$. All the singleton nodes like $(x,x)$ have value equal to 1. The system of equations is defined as follows: 

\begin{equation} \label{eq:PersonalizedWeightedSimRank}
s(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b\\
InitStore[(a,b)] & \mbox{if } (a,b) \in InitStore\\
\frac{C}{W_{I}(a)W_{I}(b)} \sum_{i=1}^{|I(a)|} \sum_{j=1}^{|I(b)|} w(I_i(a),a) \cdot w(I_j(b),b) \cdot s(I_i(a),I_j(b)) & \mbox{otherwise }
\end{array}\right.
\end{equation}
In the personalized framework, we have no constraints over the initialization as long as all values initialized are in range $[0,C]$. 

\subsection{Computing Personalized SimRank}
A solution to the equations \ref{eq:PersonalizedWeightedSimRank} for a graph $G(V,E)$ can be reached by iteration to fixed point. The method is very similar to the method to solve \ref{eq:SimRankBasic}. For each iteration $k$, we have ${|V|}^2$ entries in $R_k(\ast, \ast)$, where $R_k(a,b)$ gives the score between $a$ and $b$ on iteration $k$.
We successively compute $R_{k+1}(\ast,\ast)$ based on $R_k(\ast,\ast)$. 
We start with $R_0(\ast,\ast)$ initialized as:

\begin{equation}
R_0(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b\\
InitStore[(a,b)] & \mbox{if } (a,b) \in InitStore \\
0 & \mbox{otherwise }
\end{array}\right.
\end{equation}

\noindent
We compute $R_{k+1}(a,b)$ from $R_k(\ast,\ast)$ as follows:
\begin{equation} \label{eq:PersonalizedWeightedSimRankSolution}
\hspace*{-2cm} R_{k+1}(a,b) =
\left\{ \begin{array}{rl}
1 & \mbox{if } a=b\\
InitStore[(a,b)] & \mbox{if } (a,b) \in InitStore\\
\frac{C}{W_{I}(a)W_{I}(b)} \sum_{i=1}^{|I(a)|} \sum_{j=1}^{|I(b)|} w(I_i(a),a) \cdot w(I_j(b),b) \cdot R_k(I_i(a),I_j(b)) & \mbox{otherwise}
\end{array}\right.
\end{equation}

\subsection{Properties of Personalized SimRank}
We will now mention some important properties regarding the convergence of the personalized simrank system and accuracy estimates.

\begin{proposition}
The system of equations of Personalized SimRank has a solution, which is contructed by the iterative fixed point solution defined above. % add eqn labels here.
\end{proposition}

\begin{proposition}
The system of equations of Personalized SimRank has a unique solution. 
\end{proposition}


\begin{proposition} The difference between the SimRank score and the iterative similarity scores decreases exponentially in the number of iterations for every pair of nodes. Formally, for every iteration number $t = 0, 1, 2, \ldots$ and for every two nodes $a, b$, the following estimate holds:
\begin{align}
S(a,b) - R_{t}(a,b) \leq C^{t+1} \label{eq:convergence}
\end{align}
\end{proposition}

\noindent
We prove all the above mentioned propositions in Appendix \ref{appendix:PersonalizedSimRankProperties}.

\section{Personalized SimRank for Learning Synset Similarity}
\label{section:PersonalizedSimRankForLearningSynsetSimilarity}

%treating WordNet synsets as concepts

\subsection{Algorithm Outline}
\label{section:semiSupervisedAlgoOutline}
The personalized SimRank framework requires an underlying graph $G(V,E)$, where $V$ is the set of objects to be clustered and $E$ is the set of semantic links connecting these objects and an $InitStore$ which contains the similarity values over some pairs from $V\times V$ learnt or known beforehand. Note that the values in the $InitStore$ have an upper bound of $C$.

For learning synset similarity, $V$ is the set of synsets to be clustered and $E$ is the set of WordNet relations connecting these synsets. We use the \textit{Hypernymy}, \textit{Hyponymy}, \textit{Meronymy} and \textit{Holonymy} relations of WordNet as the semantic links. We seed the $InitStore$ as follows:
\begin{itemize}
\item We predict the similarity values of all the synset pairs which share at least one word using the Support Vector Machine learnt from synset-merging data from OntoNotes \citep{Hovy:2006} as described in section \ref{sec:ClassifierAndTraining}.
\item We transform the SVM predictions to the range $[0,1]$ using the sigmoid model learnt on the OntoNotes dataset. (see section \ref{sec:EstimatingPosteriorProbabilitiesFromSVMScores})
\item We scale the posterior probabilities obtained to range between $[0,C]$ by linear scaling, where $C$ is the SimRank decay parameter.
\end{itemize}

\subsection{Estimating Posterior Probabilities from SVM Scores}
\label{sec:EstimatingPosteriorProbabilitiesFromSVMScores}
Given training examples $x_i \in \mathbb{R}^n, i=1,\ldots,l,$ labeled by $y_i \in \{+1,-1\}$, the Support Vector Machine(SVM) computes a decision function $f(x)$ such that $sign(f(x))$ can be used to predict the label of any test example $x$.
Instead of predicting the label, many applications, as in our case: for SimRank Initialization, require a posterior class probability $Pr(y=1|x)$. 
\citep{Platt99} proposed approximating the posterior by a sigmoid function
\begin{align}
Pr(y=1|x) \approx P_{A,B}(f) \equiv \frac{1}{1+exp(Af+B)}\mbox{ , where } f=f(x)
\end{align}

To avoid overfitting of the sigmoid, an out-of-sample model is used.
If there are $N_+$ positive examples and $N_-$ negative examples in the train set, for each training example target values $t_i$s are used (instead of 1 and 0), where 
\begin{equation} \label{eq:SVMTargetValues}
t_i =
\left\{ \begin{array}{rl}
\frac{N_+ +1}{N_+ +2} & \mbox{if } y_i = +1\\
\frac{1}{N_- +2} & \mbox{if } y_i = -1\\
\end{array}\right.
\end{equation}

Let each $f_i$ be an estimate of $f(x_i)$. 
The best parameter setting $z^{\ast} = (A^{\ast},B^{\ast})$ is determined by solving the following regularized maximum likelihood problem:
\begin{align} \label{eq:regularizedMLProblem}
\displaystyle \min_{z=(A,B)} F(z) = - \sum_{i=1}^{l}\left( t_i \log(P_{A,B}(f_i)) + (1-t_i)\log(1-P_{A,B}(f_i))\right)
\end{align}

As indicated by \citep{Platt99}, any method for unconstrained optimization can be used for solving \ref{eq:regularizedMLProblem}. We use Newton's Method with backtracking, as proposed in \citep{Lin03Note}, as it avoids numerical difficulties faced by \citep{Platt99}. The pseudocode for the implementation is available in Appendix \ref{appendix:SVMProb}.

\subsection{Importance of Parameter \texorpdfstring{$C$}{TEXT} }
The parameter $C$ in Personalized SimRank affects the algorithm in many ways:
\begin{itemize}
\item \textbf{Maximum Similarity between distinct objects}: According to the SimRank equations, the maximum similarity between two distinct objects can be at most $C$.

\begin{align}
s(a,b) &= \frac{C}{W_{I}(a)W_{I}(b)} \sum_{i=1}^{|I(a)|} \sum_{j=1}^{|I(b)|} w(I_i(a),a)  \cdot w(I_j(b),b) \cdot \underbrace{s(I_i(a),I_j(b))}_{\leq 1}\\
&\leq \frac{C}{W_{I}(a)W_{I}(b)} \sum_{i=1}^{|I(a)|} \sum_{j=1}^{|I(b)|} w(I_i(a),a)  \cdot w(I_j(b),b)\\
&\leq \frac{C}{W_{I}(a)W_{I}(b)} \left( \sum_{i=1}^{|I(a)|} w(I_i(a),a) \right )  \cdot \left( \sum_{j=1}^{|I(b)|}  w(I_j(b),b) \right )\\
&\leq C
\end{align}

\item \textbf{Rate of convergence}: The rate of convergence of the iterative method to find the solution for SimRank equations is dependent on $C$ as the difference between SimRank theoretical and iterative similarity scores decreases exponentially in the number of iterations for every pair of nodes. In short, the higher the value of $C$, the slower is the convergence.
\end{itemize}

To understand the importance of the parameter $C$, we vary the value of $C$ in our experiments and empirically study the results obtained.

\section{Coarsening WordNet}
In this section we would discuss our method to cluster synsets of WordNet, which would give us coarser senses for words. The task in hand can be described as follows: Assuming we have a similarity metric which gives us similarity between each pair of synsets, we need to cluster the synsets where the granularity of the clustering can be adjusted according to the needs of the application.

We use the similarity metric learnt using the personalized SimRank model as described in section \ref{section:PersonalizedSimRankForLearningSynsetSimilarity}.
We construct a graph $G(V,E)$ where the vertices $V$ are the synsets of the WordNet graph and edges $E$ are obtained by thresholding the similarity metric.
On this graph, we find connected components, which gives us a partition over synsets.
The algorithm \ref{alg:CoarseningWordNet} summarises our method:

\begin{algorithm}[h]
\begin{algorithmic}
 \State \textbf{Input: } WordNet Graph $WN(V,E)$, Similarity Metric $Sim$ and threshold $t$
 \State \textbf{Output: } Partition over $V$ 
 \State $E' \gets \emptyset$
 \ForAll{Synset $s_i \in V$}
  \ForAll{Synset $s_j \in V$}
    \If{$Sim(s_i,s_j) \geq t$} 
    $E' \gets E' \cup (s_i,s_j)$
    \EndIf
  \EndFor
 \EndFor 
 \State $C \gets ConnectedComponents(G(V,E'))$\\
 \Return $C$
\end{algorithmic}
\caption{Coarsening WordNet}
\label{alg:CoarseningWordNet}
\end{algorithm}

We use the clustering obtained to derive coarse senses of words. For a word, all its senses in the same cluster are merged and act as a coarse sense. Algorithm \ref{alg:QueryingSenses} summarises the querying method:

\begin{algorithm}[h]
\begin{algorithmic}
 \State \textbf{Input: } WordNet Graph $WN(V,E)$, Word $w$ and Partition $P$ over $V$ 
 \State \textbf{Output: } Set of coarse senses $C$
 \State $L \gets ListSenses_{WN}(w)$
 \State $C \gets \emptyset$
 \ForAll{Synset $s_i \in L$}
  \State $C \gets C \cup \{s_i\}$
 \EndFor 
 \ForAll{Synset $s_i \in L$}
  \ForAll{Synset $s_j \in L$}
    \If{$s_i \neq s_j$ and $P(s_i,s_j) == 1$} 
    $C \gets Merge(C,s_i,s_j)$
    \EndIf
  \EndFor
 \EndFor  \\
\Return $C$
\end{algorithmic}
\caption{Querying Senses of a word}
\label{alg:QueryingSenses}
\end{algorithm}

\section{Experimental Setup and Evaluation}
\label{section:evaluation}
\subsection{Estimating Posterior Probabilities from SVM Scores}
We learn the parameters $A$ and $B$ of the sigmoid transforming SVM predictions to posterior probabilities (see section \ref{sec:EstimatingPosteriorProbabilitiesFromSVMScores}). If we use the same data set that was used to train the model we want to calibrate, we introduce unwanted bias. For example, if the model learns to perfectly discriminate the train set, then the sigmoid transformation will output just a binary 0,1 function. So we need to use an independent calibration set in order to get good posterior probabilities \citep{Niculescu-Mizil:2005}.

We address this problem by calibrating on an independently generated random balanced subsets from OntoNotes (see section \ref{sec:OntoNotesDataset}). The SVM predictions are obtained using the SVMs trained over random subsets of the OntoNotes data (see section \ref{section:SupervisedExperimentalSetupAndEvaluation}). Since all the SVMs were trained on randomly generated datasets, we selected the SVM that performed the best in cross validation.

The values of $A$ and $B$ obtained are -1.1655 and 0.0222 respectively. Using these values, the SVM prediction of value 0 gets mapped to 0.4944. 

\subsection{Semi-Supervised Similarity Learning}
We learn similarity models using the SimRank variant described in section \ref{section:semiSupervisedAlgoOutline}. \citep{Jeh02simrank} use $C=0.8$ and report that 5-6 iterations are enough. \citep{LizorkinSimrank} suggest to use lower values of $C$ or more number of iterations. We vary the values taken by $C$ as 0.6, 0.7 and 0.8. We run all the systems for 10 iterations to avoid convergence issues. 

We use the \textit{Hypernymy}, \textit{Hyponymy}, \textit{Meronymy} and \textit{Holonymy} relations of WordNet as the semantic links. All the semantic links used in all the experiments have uniform weight unity. For implementation, we used EZGraph Java library\footnote{ezgraph - Easy to Use Graph Analysis Library:  \url{https://code.google.com/p/ezgraph/}}.

\subsection{Coarsening WordNet}
We assess the effect of automatic synset clustering on the English all-words task at Senseval-3 \citep{Senseval3AllWordsTask} (this evaluation is similar to the evaluation used by \citep{Navigli06meaningfulclustering} and \citep{snow07mergesense}). The task required WSD systems to provide a sense choice for 2,081 content words in a set of 301 sentences from the fiction, story, news and editorial domains.

We consider the three best ranking WSD systems - GAMBL \citep{decadt-EtAl:2004:Senseval-3}, SenseLearner \citep{mihalcea-faruque:2004:Senseval-3} and Koc University \citep{yuret:2004:Senseval-3} - and the best unsupervised system, namely IRST-DDD \citep{strapparava-gliozzo-giuliano:2004:Senseval-3} submitted in the task. A guess by the system is given full credit if it was either the correct answer or if it was in the same cluster as the correct answer.

Clearly any amount of clustering will only improve the WSD performance. Therefore to account for this natural improvement and consider only the effect of our particular clustering, we calculate the score for a random clustering at the same granularity as our clustering and study the improvement over random clustering instead. 

Score for a random clustering is calculated as follows: Let the word to be diambiguated have $N$ senses, each mapped to a unique synset. Let the clustering of these $N$ synsets on a particular granularity give us $k$ clusters $C_1,\ldots C_k$. The expectation that an incorrectly chosen sense and the actual correct sense would be in cluster $C_i$  in this clustering is $\frac{|C_i|(|C_i|-1)}{N(N-1)}$. Using linearity of expectation, we can say that the chances of the two synsets belonging to same cluster would be 
\begin{equation}
\frac{\sum_{i=1}^{k} |C_i|(|C_i|-1) }{N(N-1)}
\end{equation}

We experiment with $C$ = 0.6, 0.7 and 0.8. The SVM probability boundaries when scaled to $[0,C]$ for these values are 0.30, 0.35 and 0.40. So for finding the threshold giving the best improvement against random clustering baseline, we use the search space $[C-0.35, C]$. The performance of the systems at these thresholds for different values of $C$ is reported in tables \ref{tab:wsdImprovement0.6}, \ref{tab:wsdImprovement0.7} and \ref{tab:wsdImprovement0.8}.

\begin{center}
\begin{longtable}{| c || c | c | c | c | c |}      
    \hline
    System & F-Score & Threshold & CCC & Random & Improvement \\ \hline
    GAMBL & 0.7116 & 0.36 & 0.9031 & 0.8424 & 0.0607 \\ \hline
    SenseLearner & 0.7104 & 0.37 & 0.8824 & 0.8305 & 0.0518 \\ \hline
    KOC University & 0.7191 & 0.37 & 0.8924 & 0.8314 & 0.0610 \\ \hline
    IRST-DDD & 0.6367 & 0.35 & 0.8731 & 0.8013 & 0.0718 \\ \hline
    \caption{Improvement in Senseval-3 WSD performance using Connected Component Clustering Vs Random Clustering at the same granularity with C = 0.6}
  \label{tab:wsdImprovement0.6}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{| c || c | c | c | c | c |}      
    \hline
    System & F-Score & Threshold & CCC & Random & Improvement \\ \hline
    GAMBL & 0.7116 & 0.52 & 0.8453 & 0.7864 & 0.0589 \\ \hline
    SenseLearner & 0.7104 & 0.49 & 0.8541 & 0.8097 & 0.0444 \\ \hline
    KOC University & 0.7191 & 0.52 & 0.8448 & 0.7911 & 0.0538 \\ \hline
    IRST-DDD & 0.6367 & 0.49 & 0.7970 & 0.7402 & 0.0568 \\ \hline
    \caption{Improvement in Senseval-3 WSD performance using Connected Component Clustering Vs Random Clustering at the same granularity with C = 0.7}
  \label{tab:wsdImprovement0.7}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{| c || c | c | c | c | c |}      
    \hline
    System & F-Score & Threshold & CCC & Random & Improvement \\ \hline
    GAMBL & 0.7116 & 0.59 & 0.8419 & 0.7843 & 0.0577 \\ \hline
    SenseLearner & 0.7104 & 0.56 & 0.8439 & 0.7984 & 0.0455 \\ \hline
    KOC University & 0.7191 & 0.59 & 0.8414 & 0.7879 & 0.0535 \\ \hline
    IRST-DDD & 0.6367 & 0.47& 0.8881 & 0.8324 & 0.0557 \\ \hline
    \caption{Improvement in Senseval-3 WSD performance using Connected Component Clustering Vs Random Clustering at the same granularity with C = 0.8}
  \label{tab:wsdImprovement0.8}
\end{longtable}
\end{center}

Commenting theoretically about the impact of $C$ on the performance is tough as by changing $C$ we are changing all the ${|V|}^2$ simultaneous equations to be solved. Empirically we observe that improvements over baseline keep on decreasing on increasing $C$ across all the systems. It might be because of the slow convergence of SimRank for higher values of $C$.

We observe from the figures \ref{fig:supervisedSystemsImprovement} and \ref{fig:unsupervisedSystemsImprovement} that by varying thresholds, the improvement of the Connected Components Clustering over the random clustering baseline at the same granularity first increases and then decreases.

Across supervised and unsupervised systems, we observe that the unsupervised systems obtain higher improvements than the supervised systems which can be attributed to fact that the unsupervised system used was underperforming compared to the supervised systems in the fine grained WSD task setting.

\begin{figure}
\centering
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledSupervised6.pdf}\label{superviseda}}
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledSupervised7.pdf}\label{supervisedb}}
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledSupervised8.pdf}\label{supervisedc}}
\caption{Improvement in average performance of best 3 Supervised Systems in Senseval-3 using Connected Component Clustering Vs Random Clustering at the same granularity with C = (a) 0.6, (b) 0.7 and (c) 0.8}
\label{fig:supervisedSystemsImprovement}
\end{figure}

\begin{figure}
\centering
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledUnsupervised6.pdf}\label{unsuperviseda}}
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledUnsupervised7.pdf}\label{unsupervisedb}}
\subfigure[]{\includegraphics[width=2.9in]{SVMScaledUnsupervised8.pdf}\label{unsupervisedc}}
\caption{Improvement in performance of best Unupervised System in Senseval-3 using Connected Component Clustering Vs Random Clustering at the same granularity with C = (a) 0.6, (b) 0.7 and (c) 0.8}
\label{fig:unsupervisedSystemsImprovement}
\end{figure}

\section{Conclusions and Future Work}

\subsection{Conclusions}
The method discussed in the chapter learns a model for calculating synset similarity utilizing the taxonomy information and information learnt from manually obtained sense clustering. The framework obtained is generic and can be applied to other POS as well.

For coarsening senses, we proposed one of the simplest approaches to cluster senses but it can be made to work with any clustering algorithm to generate coarse senses. We show that the clustering obtained by partitioning synsets in  connected components gives us a maximum improvement of 5.78\% on supervised systems and 7.18\% on unsupervised system.

\subsection{Future Work}

\subsubsection{Differentiating WordNet relations}`
We use the WordNet relations \textit{Hypernymy}, \textit{Hyponymy}, \textit{Meronymy} and \textit{Holonymy} without any differentiation i.e. weights of all the links are unity. If we can grade the weights of the relations based on their relative importances, we can expect an improvement in the system. One way can be to perform cognitive experiments and obtain the weights of relations from the feedback of the annotators. An alternative way can be learn weights in a task based setting using an approach similar to \citep{Navigli05SSI}.

\subsubsection{Speeding up the implementation}
We used the naive implementation of SimRank, proposed in \citep{Jeh02simrank}, for implementing Personalized SimRank. Faster approximate scalable implementations of SimRank like \citep{FogarasSimRank}, \citep{LizorkinSimrank} etc. can also be adapted appropriately for personalization and thus speed up the algorithm.

