\BOOKMARK [0][-]{figure.caption.1}{Abstract}{}% 1
\BOOKMARK [0][-]{chapter*.4}{List of Tables}{}% 2
\BOOKMARK [0][-]{chapter*.5}{List of Figures}{}% 3
\BOOKMARK [0][-]{chapter*.6}{List of Algorithms}{}% 4
\BOOKMARK [0][-]{chapter.7}{1 Introduction}{}% 5
\BOOKMARK [1][-]{section.9}{1.1 Motivation}{chapter.7}% 6
\BOOKMARK [2][-]{subsection.10}{1.1.1 Inability to preserve word ordering}{section.9}% 7
\BOOKMARK [2][-]{subsection.11}{1.1.2 Lack of similarity measures}{section.9}% 8
\BOOKMARK [2][-]{subsection.12}{1.1.3 Compositionality of distributed word vectors}{section.9}% 9
\BOOKMARK [1][-]{section.13}{1.2 Problem Statement}{chapter.7}% 10
\BOOKMARK [1][-]{section.15}{1.3 Organization of Thesis}{chapter.7}% 11
\BOOKMARK [0][-]{chapter.16}{2 Related Work}{}% 12
\BOOKMARK [1][-]{section.17}{2.1 Text Representation}{chapter.16}% 13
\BOOKMARK [2][-]{subsection.18}{2.1.1 Bag of Words}{section.17}% 14
\BOOKMARK [2][-]{subsection.24}{2.1.2 Dimensionality Reduction and Feature Selection}{section.17}% 15
\BOOKMARK [1][-]{section.33}{2.2 Learning Algorithms}{chapter.16}% 16
\BOOKMARK [2][-]{subsection.34}{2.2.1 Document Categorization using Binary Classifiers}{section.33}% 17
\BOOKMARK [2][-]{subsection.39}{2.2.2 Document Categorization with Single Joint Classifier}{section.33}% 18
\BOOKMARK [0][-]{chapter.44}{3 Distributed Document Embeddings}{}% 19
\BOOKMARK [1][-]{section.45}{3.1 Why use Distributed Word Representations?}{chapter.44}% 20
\BOOKMARK [1][-]{section.48}{3.2 Background on Word Embeddings}{chapter.44}% 21
\BOOKMARK [2][-]{subsection.49}{3.2.1 Neural Probabilistic Language Model}{section.48}% 22
\BOOKMARK [2][-]{subsection.56}{3.2.2 Log-Linear Models}{section.48}% 23
\BOOKMARK [3][-]{subsubsection.57}{3.2.2.1 Continuous Bag-of-Words}{subsection.56}% 24
\BOOKMARK [3][-]{subsubsection.62}{3.2.2.2 Continuous Skip-gram}{subsection.56}% 25
\BOOKMARK [3][-]{subsubsection.65}{3.2.2.3 Dependency-based Word Embeddings}{subsection.56}% 26
\BOOKMARK [1][-]{section.67}{3.3 Document Embeddings}{chapter.44}% 27
\BOOKMARK [2][-]{subsection.70}{3.3.1 Problem Setup}{section.67}% 28
\BOOKMARK [2][-]{subsection.71}{3.3.2 Our Model}{section.67}% 29
\BOOKMARK [3][-]{subsubsection.76}{3.3.2.1 Projection Layer \(Context Representation\)}{subsection.71}% 30
\BOOKMARK [3][-]{subsubsection.78}{3.3.2.2 Estimating Prediction Probability}{subsection.71}% 31
\BOOKMARK [3][-]{subsubsection.83}{3.3.2.3 Training Objective}{subsection.71}% 32
\BOOKMARK [3][-]{subsubsection.87}{3.3.2.4 Noise Contrastive Estimation}{subsection.71}% 33
\BOOKMARK [3][-]{subsubsection.91}{3.3.2.5 New Training Objective}{subsection.71}% 34
\BOOKMARK [3][-]{subsubsection.95}{3.3.2.6 Parameter Estimation}{subsection.71}% 35
\BOOKMARK [3][-]{subsubsection.122}{3.3.2.7 Hyper-parameters}{subsection.71}% 36
\BOOKMARK [0][-]{chapter.129}{4 Multi-Label Document Categorization}{}% 37
\BOOKMARK [1][-]{section.130}{4.1 Logistic Regression for Multi-label Document Categorization}{chapter.129}% 38
\BOOKMARK [2][-]{subsection.131}{4.1.1 Training Data}{section.130}% 39
\BOOKMARK [2][-]{subsection.132}{4.1.2 Logistic Regression Model}{section.130}% 40
\BOOKMARK [3][-]{subsubsection.136}{4.1.2.1 Training Objective}{subsection.132}% 41
\BOOKMARK [3][-]{subsubsection.143}{4.1.2.2 Parameter Estimation}{subsection.132}% 42
\BOOKMARK [1][-]{section.151}{4.2 Similarity to Relational Learning}{chapter.129}% 43
\BOOKMARK [1][-]{section.155}{4.3 Advantages of Logistic Regression Learning Algorithm}{chapter.129}% 44
\BOOKMARK [0][-]{chapter.160}{5 Datasets and Evaluations}{}% 45
\BOOKMARK [1][-]{section.161}{5.1 Datasets}{chapter.160}% 46
\BOOKMARK [2][-]{subsection.162}{5.1.1 Reuters-21578}{section.161}% 47
\BOOKMARK [2][-]{subsection.164}{5.1.2 Wikipedia Datasets}{section.161}% 48
\BOOKMARK [1][-]{section.167}{5.2 Experimental Setup}{chapter.160}% 49
\BOOKMARK [1][-]{section.172}{5.3 Results}{chapter.160}% 50
\BOOKMARK [2][-]{subsection.173}{5.3.1 Document Categorization}{section.172}% 51
\BOOKMARK [3][-]{subsubsection.174}{5.3.1.1 Reuters - 21578}{subsection.173}% 52
\BOOKMARK [3][-]{subsubsection.181}{5.3.1.2 Physics - Wikipedia}{subsection.173}% 53
\BOOKMARK [3][-]{subsubsection.188}{5.3.1.3 Biology - Wikipedia}{subsection.173}% 54
\BOOKMARK [3][-]{subsubsection.195}{5.3.1.4 Mathematics - Wikipedia}{subsection.173}% 55
\BOOKMARK [3][-]{subsubsection.202}{5.3.1.5 Sports - Wikipedia}{subsection.173}% 56
\BOOKMARK [2][-]{subsection.209}{5.3.2 Imputing Missing Categories}{section.172}% 57
\BOOKMARK [2][-]{subsection.211}{5.3.3 Estimating Similarity between Categories and Words}{section.172}% 58
\BOOKMARK [0][-]{chapter.213}{6 Conclusions and Future Work}{}% 59
\BOOKMARK [1][-]{section.214}{6.1 Future Work}{chapter.213}% 60
\BOOKMARK [2][-]{subsection.215}{6.1.1 Improving Compositionality of Word Vectors}{section.214}% 61
\BOOKMARK [2][-]{subsection.216}{6.1.2 Multi-view Supervised Representation Learning}{section.214}% 62
\BOOKMARK [0][-]{subsection.216}{Bibliography}{}% 63
